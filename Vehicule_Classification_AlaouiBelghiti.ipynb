{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vehicule_Classification_AlaouiBelghiti.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FYcgEF4Qh-T"
      },
      "source": [
        "# **Test de modèle de classification VGG16**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu7KyraItSev",
        "outputId": "ba78fbce-ae27-444d-c9b6-9a8c570f06ef"
      },
      "source": [
        "from tensorflow.python.client import device_lib\r\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 8132877174060212824, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 11145797952\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 119245245474195087\n",
              " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MeRJgIawn2e",
        "outputId": "40b5904f-0ab2-4059-a4d0-33b809022fcc"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.10)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.12.5)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "Y9DmR1Jww6sx",
        "outputId": "6e0c682f-8795-470d-ccc3-6f968cea6ffc"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0aad1057-777b-4750-8699-de494a89d022\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0aad1057-777b-4750-8699-de494a89d022\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"khawlaalaoui\",\"key\":\"abaa16a64220dc94b6dce44eadf5980a\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q3OhgbgxeU9"
      },
      "source": [
        "!mkdir -p ~/.kaggle\r\n",
        "!cp kaggle.json ~/.kaggle/\r\n",
        "\r\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e36sAx-bywjF",
        "outputId": "e0de5d6c-04cb-4a35-f051-d266280419f7"
      },
      "source": [
        "!kaggle datasets download -d mbornoe/lisa-traffic-light-dataset "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading lisa-traffic-light-dataset.zip to /content\n",
            "100% 4.21G/4.21G [01:22<00:00, 64.2MB/s]\n",
            "100% 4.21G/4.21G [01:22<00:00, 55.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEoXVLQwzbH7",
        "outputId": "94c921f6-7291-4605-95d3-c3ed5af6c1c0"
      },
      "source": [
        "from zipfile import ZipFile\r\n",
        "file_name = \"lisa-traffic-light-dataset.zip\"\r\n",
        "\r\n",
        "with ZipFile(file_name,'r') as zip:\r\n",
        "  zip.extractall()\r\n",
        "  print('Done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vHEJEedKuNI",
        "outputId": "70043883-6992-40d6-9c4d-98708d09dc4a"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\r\n",
        "\r\n",
        "model = VGG16() # Création du modèle VGG-16 implementé par Keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MnqeJPbtGmE"
      },
      "source": [
        "from keras.preprocessing.image import load_img, img_to_array\r\n",
        "from keras.applications.vgg16 import preprocess_input\r\n",
        "\r\n",
        "img = load_img('/content/daySequence1/daySequence1/frames/daySequence1--00000.jpg', target_size=(224, 224))  # Charger l'image\r\n",
        "img = img_to_array(img)  # Convertir en tableau numpy\r\n",
        "img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))  # Créer la collection d'images (un seul échantillon)\r\n",
        "img = preprocess_input(img)  # Prétraiter l'image comme le veut VGG-16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAf-GGZdte05"
      },
      "source": [
        "y = model.predict(img)  # Prédir la classe de l'image (parmi les 1000 classes d'ImageNet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNZ8lV3MtzWk",
        "outputId": "cbf11ff8-1c08-4eda-adad-e966764edca0"
      },
      "source": [
        "from keras.applications.vgg16 import decode_predictions\r\n",
        "\r\n",
        "# Afficher les 3 classes les plus probables\r\n",
        "print('Top 3 :', decode_predictions(y, top=5)[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "40960/35363 [==================================] - 0s 0us/step\n",
            "Top 3 : [('n06874185', 'traffic_light', 0.50540227), ('n03837869', 'obelisk', 0.06962101), ('n03976657', 'pole', 0.052812494), ('n03891332', 'parking_meter', 0.04191866), ('n02965783', 'car_mirror', 0.030474832)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u3_kiL_u7f4"
      },
      "source": [
        "## **Detect vehicles**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DerLBF3FRX4O",
        "outputId": "765d9d37-89d5-4e4a-8d49-d2fe3af5dcc2"
      },
      "source": [
        "import matplotlib.image as mpimg\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import pickle\r\n",
        "import cv2\r\n",
        "from skimage.feature import hog\r\n",
        "from scipy.ndimage.measurements import label\r\n",
        "from features import *\r\n",
        "%matplotlib inline\r\n",
        "from IPython.display import HTML"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3915776/45929032 bytes (8.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b8224768/45929032 bytes (17.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b12550144/45929032 bytes (27.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16785408/45929032 bytes (36.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b21102592/45929032 bytes (45.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b25165824/45929032 bytes (54.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b29409280/45929032 bytes (64.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b33628160/45929032 bytes (73.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b37781504/45929032 bytes (82.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b42033152/45929032 bytes (91.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYvcCQJxeEcN"
      },
      "source": [
        "def convert_color(img, conv='RGB2YCrCb'):\r\n",
        "    if conv == 'RGB2YCrCb':\r\n",
        "        return cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\r\n",
        "    if conv == 'BGR2YCrCb':\r\n",
        "        return cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\r\n",
        "    if conv == 'RGB2LUV':\r\n",
        "        return cv2.cvtColor(img, cv2.COLOR_RGB2LUV)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EwT_gsteHNw"
      },
      "source": [
        "def add_heat(heatmap, bbox_list):\r\n",
        "    # Iterate through list of bboxes\r\n",
        "    for box in bbox_list:\r\n",
        "        # Add += 1 for all pixels inside each bbox\r\n",
        "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\r\n",
        "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\r\n",
        "\r\n",
        "    # Return updated heatmap\r\n",
        "    return heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWSKWwcseK7A"
      },
      "source": [
        "def apply_threshold(heatmap, threshold):\r\n",
        "    # Zero out pixels below the threshold\r\n",
        "    heatmap[heatmap <= threshold] = 0\r\n",
        "    # Return thresholded map\r\n",
        "    return heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swO5qXNceM2Q"
      },
      "source": [
        "def draw_labeled_bboxes(img, labels):\r\n",
        "    box_list = []\r\n",
        "    \r\n",
        "    # Iterate through all detected cars\r\n",
        "    for car_number in range(1, labels[1]+1):\r\n",
        "        # Find pixels with each car_number label value\r\n",
        "        nonzero = (labels[0] == car_number).nonzero()\r\n",
        "        # Identify x and y values of those pixels\r\n",
        "        nonzeroy = np.array(nonzero[0])\r\n",
        "        nonzerox = np.array(nonzero[1])\r\n",
        "        # Define a bounding box based on min/max x and y\r\n",
        "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\r\n",
        "        # Draw the box on the image\r\n",
        "        # could be [0,255] or [0,1] depending how the file was read in\r\n",
        "        cv2.rectangle(img, bbox[0], bbox[1], (255,0,0), 6)\r\n",
        "        \r\n",
        "        box_list.append(bbox)\r\n",
        "\r\n",
        "    return img, box_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yglht9ZceNuT"
      },
      "source": [
        "def find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins):\r\n",
        "    \r\n",
        "    #draw_img = np.copy(img)\r\n",
        "    img = img.astype(np.float32)/255\r\n",
        "    heat = np.zeros_like(img[:,:,0]).astype(np.float)\r\n",
        "    bboxes = []\r\n",
        "    \r\n",
        "    img_tosearch = img[ystart:ystop,:,:]\r\n",
        "    ctrans_tosearch = convert_color(img_tosearch, conv='RGB2YCrCb')\r\n",
        "    if scale != 1:\r\n",
        "        imshape = ctrans_tosearch.shape\r\n",
        "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\r\n",
        "        \r\n",
        "    ch1 = ctrans_tosearch[:,:,0]\r\n",
        "    ch2 = ctrans_tosearch[:,:,1]\r\n",
        "    ch3 = ctrans_tosearch[:,:,2]\r\n",
        "\r\n",
        "    # Define blocks and steps as above\r\n",
        "    nxblocks = (ch1.shape[1] // pix_per_cell)-1\r\n",
        "    nyblocks = (ch1.shape[0] // pix_per_cell)-1 \r\n",
        "    nfeat_per_block = orient*cell_per_block**2\r\n",
        "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\r\n",
        "    window = 64\r\n",
        "    nblocks_per_window = (window // pix_per_cell)-1 \r\n",
        "    cells_per_step = 2  # Instead of overlap, define how many cells to step\r\n",
        "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\r\n",
        "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step\r\n",
        "    \r\n",
        "    # Compute individual channel HOG features for the entire image\r\n",
        "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\r\n",
        "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\r\n",
        "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\r\n",
        "    \r\n",
        "    for xb in range(nxsteps):\r\n",
        "        for yb in range(nysteps):\r\n",
        "            ypos = yb*cells_per_step\r\n",
        "            xpos = xb*cells_per_step\r\n",
        "            # Extract HOG for this patch\r\n",
        "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \r\n",
        "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \r\n",
        "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \r\n",
        "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\r\n",
        "\r\n",
        "            xleft = xpos*pix_per_cell\r\n",
        "            ytop = ypos*pix_per_cell\r\n",
        "\r\n",
        "            # Extract the image patch\r\n",
        "            subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\r\n",
        "          \r\n",
        "            # Get color features\r\n",
        "            spatial_features = bin_spatial(subimg, size=spatial_size)\r\n",
        "            hist_features = color_hist(subimg, nbins=hist_bins)\r\n",
        "\r\n",
        "            # Scale features and make a prediction\r\n",
        "            test_features = X_scaler.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))    \r\n",
        "            #test_features = X_scaler.transform(np.hstack((shape_feat, hist_feat)).reshape(1, -1))    \r\n",
        "            test_prediction = svc.predict(test_features)\r\n",
        "            \r\n",
        "            if test_prediction == 1:\r\n",
        "                xbox_left = np.int(xleft*scale)\r\n",
        "                ytop_draw = np.int(ytop*scale)\r\n",
        "                win_draw = np.int(window*scale)\r\n",
        "                bboxes.append(((xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart)))\r\n",
        "                \r\n",
        "                #if you want to draw hog subsampling boxes\r\n",
        "                #cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart),(0,0,255),6)\r\n",
        "    \r\n",
        "    #add up heat overlap \r\n",
        "    heatmap = add_heat(heat, bboxes)\r\n",
        "                \r\n",
        "    return heatmap, bboxes #, draw_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qmup2F_reQny"
      },
      "source": [
        "def track_vehicles(img):\r\n",
        "    \r\n",
        "    global draw_img_prev, bbox_list_prev, labels_prev, heatmap_sum\r\n",
        "    global first_frame, frame_count\r\n",
        "    \r\n",
        "    model_pickle = pickle.load(open('/content/00-training.pkl', 'rb'))\r\n",
        "    svc = model_pickle['svc']\r\n",
        "    X_scaler = model_pickle['scaler']\r\n",
        "    orient = model_pickle['orient']\r\n",
        "    pix_per_cell = model_pickle['pix_per_cell'] \r\n",
        "    cell_per_block = model_pickle['cell_per_block']\r\n",
        "    spatial_size = model_pickle['spatial_size']\r\n",
        "    hist_bins = model_pickle['hist_bins']\r\n",
        "    \r\n",
        "    #this could be changed relative to image size\r\n",
        "    ystart = 400\r\n",
        "    ystop = 420\r\n",
        "    \r\n",
        "    if first_frame:\r\n",
        "        \r\n",
        "        #initialize the running average heatmap\r\n",
        "        heatmap_sum = np.zeros_like(img[:,:,0]).astype(np.float)\r\n",
        "        \r\n",
        "        for scale in (1.0,1.5,2.0):\r\n",
        "            \r\n",
        "            #as the image scale gets bigger, the ROI needs to extend\r\n",
        "            ystop = ystop + 75\r\n",
        "\r\n",
        "            heatmap, bboxes = find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, \r\n",
        "                                        pix_per_cell, cell_per_block, spatial_size, hist_bins)\r\n",
        "            #sum up heatmap for all scales\r\n",
        "            heatmap_sum = np.add(heatmap_sum,heatmap)\r\n",
        "        \r\n",
        "        heatmap = apply_threshold(heatmap_sum, 2)\r\n",
        "        heatmap = np.clip(heatmap, 0, 1)\r\n",
        "        labels = label(heatmap)\r\n",
        "        draw_img, bbox_list = draw_labeled_bboxes(np.copy(img), labels)\r\n",
        "\r\n",
        "        draw_img_prev = draw_img\r\n",
        "        bbox_list_prev = bbox_list\r\n",
        "        labels_prev = labels\r\n",
        "\r\n",
        "        first_frame = False\r\n",
        "    \r\n",
        "        return draw_img\r\n",
        "    \r\n",
        "    if frame_count <= 2:\r\n",
        "        \r\n",
        "        frame_count += 1\r\n",
        "        \r\n",
        "        #reset ROI\r\n",
        "        ystop = 420\r\n",
        "        \r\n",
        "        for scale in (1.0,1.5,2.0):\r\n",
        "\r\n",
        "            ystop = ystop + 75\r\n",
        "            heatmap, bboxes = find_cars(img, ystart, ystop, scale, svc, X_scaler,\r\n",
        "                                                            orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\r\n",
        "            heatmap_sum = np.add(heatmap_sum,heatmap)\r\n",
        "            draw_img = np.copy(img)\r\n",
        "        \r\n",
        "        #draw old boxes\r\n",
        "        for unique_car in range(1, labels_prev[1]+1):\r\n",
        "            draw_img = cv2.rectangle(draw_img, bbox_list_prev[unique_car-1][0],\r\n",
        "                                     bbox_list_prev[unique_car-1][1], (255,0,0), 6)\r\n",
        "        return draw_img\r\n",
        "    \r\n",
        "    heatmap = apply_threshold(heatmap_sum,2)\r\n",
        "    heatmap = np.clip(heatmap, 0, 255)\r\n",
        "    labels = label(heatmap)   \r\n",
        "    draw_img, bbox_list = draw_labeled_bboxes(np.copy(img), labels)   \r\n",
        "    \r\n",
        "    draw_img_prev = draw_img\r\n",
        "    bbox_list_prev = bbox_list\r\n",
        "    labels_prev = labels\r\n",
        "    \r\n",
        "    #reset heatmap sum and frame_count\r\n",
        "    heatmap_sum = np.zeros_like(img[:,:,0]).astype(np.float)\r\n",
        "    frame_count = 0\r\n",
        "    \r\n",
        "    return draw_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "E04ArdpueVvZ",
        "outputId": "6c082393-6a4d-4a60-ab5d-e2bf530d8477"
      },
      "source": [
        "import glob\r\n",
        "images = glob.glob('/content/sample-dayClip6/sample-dayClip6/frames/*jpg')\r\n",
        "for index, image in enumerate(images):\r\n",
        "    img = mpimg.imread(image)\r\n",
        "    global first_frame, frame_count\r\n",
        "    frame_count = 0\r\n",
        "    first_frame = True\r\n",
        "    draw = track_vehicles(img)\r\n",
        "    plt.figure()\r\n",
        "    plt.imshow(draw);\r\n",
        "    plt.tight_layout()\r\n",
        "    plt.savefig('output_images{}'.format(index))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}